{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code_cr             object\n",
       "dept                 int64\n",
       "effectif             int64\n",
       "ca_total_FL          int64\n",
       "ca_export_FK       float64\n",
       "risque              object\n",
       "endettement        float64\n",
       "evo_benefice       float64\n",
       "ratio_benef        float64\n",
       "evo_effectif       float64\n",
       "evo_risque           int64\n",
       "age                  int64\n",
       "type_com            object\n",
       "activite            object\n",
       "actionnaire         object\n",
       "forme_jur_simpl     object\n",
       "chgt_dir             int64\n",
       "rdv                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Turn interactive plotting off\n",
    "plt.ioff()\n",
    "\n",
    "# read input text and put data inside a data frame\n",
    "data = pd.read_csv(\"../data/base_prospect_clean.csv\",encoding=\"ISO-8859-1\")\n",
    "# prospect =  pd.DataFrame(prospect)\n",
    "data.head\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "effectif             int64\n",
       "ca_total_FL          int64\n",
       "ca_export_FK       float64\n",
       "risque              object\n",
       "endettement        float64\n",
       "evo_benefice       float64\n",
       "ratio_benef        float64\n",
       "evo_effectif       float64\n",
       "evo_risque           int64\n",
       "age                  int64\n",
       "type_com            object\n",
       "activite            object\n",
       "actionnaire         object\n",
       "forme_jur_simpl     object\n",
       "chgt_dir             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "feature_names  = data.columns.values[2:-1]\n",
    "X = data[feature_names]\n",
    "y = data[\"code_cr\"]\n",
    "#La liste des caisses rÃ©gionales\n",
    "lst_caisse=data['code_cr'].unique()\n",
    "\n",
    "\n",
    "X_cat = X.select_dtypes(exclude=['float64','int64'])\n",
    "\n",
    "X_cat.head\n",
    "\n",
    "# Disjonction with OneHotEncoder\n",
    "encoder.fit(X_cat)\n",
    "X_cat = encoder.transform(X_cat).toarray()\n",
    "\n",
    "X.dtypes\n",
    "\n",
    "\n",
    "# X_num_cat = pd.concat([pd.DataFrame(X_num), pd.DataFrame(X_cat)], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# 3 - Cluster\n",
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "# TODO\n",
    "X_num = X.select_dtypes(include=['float64','int64'])\n",
    "\n",
    "X_num_norm = scaler.fit_transform(X_num)\n",
    "# print(X_norm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['effectif', 'ca_total_FL', 'ca_export_FK', 'risque', 'endettement',\n",
      "       'evo_benefice', 'ratio_benef', 'evo_effectif', 'evo_risque', 'age',\n",
      "       'type_com', 'activite', 'actionnaire', 'forme_jur_simpl', 'chgt_dir'],\n",
      "      dtype='object')\n",
      "[] [0.0767573765577459, 0.14167604012758722, 0.20452221865708542, 0.266670360015165, 0.31925027916195003, 0.3554423974924842, 0.3895667246345714, 0.424090311768097, 0.43818303798177105, 0.45806373677741785, 0.49463013856852595, 0.5062476099639682, 0.5134274782691077, 0.5218605481723363, 0.5408611594123002, 0.5531611767294333, 0.5664597899037577, 0.573400971125688]\n"
     ]
    }
   ],
   "source": [
    "X_num_cat = pd.concat([pd.DataFrame(X_num_norm), pd.DataFrame(X_cat)], axis=1).to_numpy()\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "print(X.columns)\n",
    "X_num_cat\n",
    "\n",
    "\n",
    "\n",
    "# Compute R-square, i.e. V_inter/V\n",
    "from R_square_clustering import r_square\n",
    "from purity import purity_score\n",
    "\n",
    "# Plot elbow graphs for KMeans using R square and purity scores\n",
    "lst_k=range(2,20)\n",
    "lst_rsq = []\n",
    "lst_purity = []\n",
    "for k in lst_k:\n",
    "    est=KMeans(n_clusters=k)\n",
    "    est.fit(X_num_cat)\n",
    "    lst_rsq.append(r_square(X_num_cat, est.cluster_centers_,est.labels_,k))\n",
    "    # TODO: complete lst_purity\n",
    "    \n",
    "print(lst_purity, lst_rsq)\n",
    "fig = plt.figure()\n",
    "plt.plot(lst_k, lst_rsq, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('RSQ')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.savefig('fig/k-means_elbow_method')\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def bench_k_means(kmeans, name, data, labels):\n",
    "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmeans : KMeans instance\n",
    "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
    "        already set.\n",
    "    name : str\n",
    "        Name given to the strategy. It will be used to show the results in a\n",
    "        table.\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The data to cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        The labels used to compute the clustering metrics which requires some\n",
    "        supervision.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
    "    fit_time = time() - t0\n",
    "    results = [name, fit_time, estimator[-1].inertia_]\n",
    "\n",
    "    # Define the metrics which require only the true labels and estimator\n",
    "    # labels\n",
    "    clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "        metrics.adjusted_rand_score,\n",
    "        metrics.adjusted_mutual_info_score,\n",
    "    ]\n",
    "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
    "\n",
    "    # The silhouette score requires the full dataset\n",
    "    results += [\n",
    "        metrics.silhouette_score(\n",
    "            data,\n",
    "            estimator[-1].labels_,\n",
    "            metric=\"euclidean\",\n",
    "            sample_size=300,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Show the results\n",
    "    formatter_result = (\n",
    "        \"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\"\n",
    "    )\n",
    "    print(formatter_result.format(*results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 18\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# print centroids associated with several countries\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# centroid of the entire dataset\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# est: KMeans model fit to the dataset\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# print(est.cluster_centers_)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m lst_caisse:\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mprint\u001b[39m(est\u001b[39m.\u001b[39;49mlabels_[y\u001b[39m.\u001b[39;49mloc[y\u001b[39m==\u001b[39;49mname]])\n\u001b[1;32m     19\u001b[0m     \u001b[39m# num_cluster = est.labels_[y.loc[y==name].index][0]\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[39m# print('Num cluster for '+name+': '+str(num_cluster))\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39m# print('\\tlist of countries: '+', '.join(y.iloc[np.where(est.labels_==num_cluster)].values))\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39m# print('\\tcentroid: '+str(est.cluster_centers_[num_cluster]))\u001b[39;00m\n\u001b[1;32m     23\u001b[0m lst_caisse\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(82 * \"_\")\n",
    "print(\"init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\")\n",
    "\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=8, n_init=4, random_state=0)\n",
    "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=X_num_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_blobs\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm as cm\n",
    "# import numpy as np\n",
    "# import matplotlib.style as style\n",
    "\n",
    "# X = X_cat\n",
    "\n",
    "# range_n_clusters = [4, 5, 6,7,8]\n",
    "# silhouette_avg_n_clusters = []\n",
    "\n",
    "# for n_clusters in range_n_clusters:\n",
    "#     # Create a subplot with 1 row and 2 columns\n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "#     fig.set_size_inches(18, 7)\n",
    "\n",
    "#     # The 1st subplot is the silhouette plot\n",
    "#     # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "#     # lie within [-0.1, 1]\n",
    "#     ax1.set_xlim([-0.1, 1])\n",
    "#     # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "#     # plots of individual clusters, to demarcate them clearly.\n",
    "#     ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "#     # Initialize the clusterer with n_clusters value and a random generator\n",
    "#     # seed of 10 for reproducibility.\n",
    "#     clusterer = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "#     cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "#     # The silhouette_score gives the average value for all the samples.\n",
    "#     # This gives a perspective into the density and separation of the formed\n",
    "#     # clusters\n",
    "#     silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "#     print(\"For n_clusters =\", n_clusters,\n",
    "#           \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "#     silhouette_avg_n_clusters.append(silhouette_avg)\n",
    "#     # Compute the silhouette scores for each sample\n",
    "#     sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "#     y_lower = 10\n",
    "#     for i in range(n_clusters):\n",
    "#         # Aggregate the silhouette scores for samples belonging to\n",
    "#         # cluster i, and sort them\n",
    "#         ith_cluster_silhouette_values = \\\n",
    "#             sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "#         ith_cluster_silhouette_values.sort()\n",
    "\n",
    "#         size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "#         y_upper = y_lower + size_cluster_i\n",
    "\n",
    "#         color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "#         ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "#                           0, ith_cluster_silhouette_values,\n",
    "#                           facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "#         # Label the silhouette plots with their cluster numbers at the middle\n",
    "#         ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "#         # Compute the new y_lower for next plot\n",
    "#         y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "#     ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "#     ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "#     ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "#     # The vertical line for average silhouette score of all the values\n",
    "#     ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "#     ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "#     ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "#     # 2nd Plot showing the actual clusters formed\n",
    "#     colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "#     ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "#                 c=colors, edgecolor='k')\n",
    "\n",
    "#     # Labeling the clusters\n",
    "#     centers = clusterer.cluster_centers_\n",
    "#     # Draw white circles at cluster centers\n",
    "#     ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "#                 c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "#     for i, c in enumerate(centers):\n",
    "#         ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "#                     s=50, edgecolor='k')\n",
    "\n",
    "#     ax2.set_title(\"The visualization of the clustered data.\")\n",
    "#     ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "#     ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "#     plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "#                   \"with n_clusters = %d\" % n_clusters),\n",
    "#                  fontsize=14, fontweight='bold')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# style.use(\"fivethirtyeight\")\n",
    "# plt.plot(range_n_clusters, silhouette_avg_n_clusters)\n",
    "# plt.xlabel(\"Number of Clusters (k)\")\n",
    "# plt.ylabel(\"silhouette score\")\n",
    "# plt.savefig('fig/k-means_elbow_method')\n",
    "\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "274cf1cd44d75c296ad468b847379e30b7fbc6e3132e4e5e37d60078b9b24cbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
